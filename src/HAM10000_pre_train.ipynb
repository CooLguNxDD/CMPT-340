{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# In this notebook, we are going to implement VGG16 model to analysis the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import gc\n",
    "from glob import glob\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import tensorflow as tf\n",
    "import efficientnet.tfkeras as ef\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.applications.vgg16 import VGG16\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load metadata.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/HAM10000_metadata.csv', delimiter=',')\n",
    "df.dataframeName = 'HAM10000_metadata.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "label_encoder.fit(df['dx'])\n",
    "print(list(label_encoder.classes_))\n",
    "df['label'] = label_encoder.transform(df[\"dx\"])\n",
    "print(df.sample(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Features to label\n",
    "akiex -> 0\n",
    "bcc -> 1\n",
    "bkl -> 2\n",
    "df -> 3\n",
    "mel -> 4\n",
    "nv -> 5\n",
    "vasc -> 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "features_dict = {0:\"akiex\",1:\"bcc\",2:\"bkl\",3:\"df\", 4:\"mel\",5:\"nv\",6:\"vasc\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocess image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "image_size = 150 #the size that the image will resize to\n",
    "image_path = {os.path.splitext(os.path.basename(x))[0]: x\n",
    "              for x in glob(os.path.join('../data/','*','*.jpg'))}\n",
    "#image path\n",
    "df['path'] = df['image_id'].map(lambda id: image_path.get(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#it takes time to process the image\n",
    "df['image_64'] = df['path'].map(lambda path:Image.open(path).resize((image_size,image_size)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Print some images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "index = 1\n",
    "for image in df['image_64'].head(10):\n",
    "    plots = plt.subplot(2,5,index)\n",
    "    plots.imshow(image)\n",
    "    index+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image to array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df['image'] = df['image_64'].map(lambda image: np.asarray(image))\n",
    "data = np.asarray(df['image'].to_list()).astype(\"short\")\n",
    "label_to_one_hot = to_categorical(df['label'], num_classes=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split train, test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#80% data for training\n",
    "#20% data for testing\n",
    "train_data,test_data,train_label,test_label = train_test_split(data,label_to_one_hot,test_size=0.2,random_state=87,stratify=label_to_one_hot)\n",
    "\n",
    "#80% train data for training\n",
    "#20% train data for validation\n",
    "train_data,valid_data,train_label,valid_label = train_test_split(train_data,train_label,test_size=0.2,random_state=87,stratify=train_label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate more Image for training\n",
    "# Center and normalize the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "data_gen = ImageDataGenerator(rescale=1.0/255., featurewise_center=True,\n",
    "    rotation_range=50 ,horizontal_flip=True,vertical_flip=True,\n",
    "    height_shift_range=0.2,width_shift_range=0.2, shear_range=0.2)\n",
    "data_gen.fit(train_data)\n",
    "\n",
    "valid_data_gen = ImageDataGenerator(rescale=1.0/255., featurewise_center=True,\n",
    "    rotation_range=50 ,horizontal_flip=True,vertical_flip=True,\n",
    "    height_shift_range=0.2,width_shift_range=0.2, shear_range=0.2)\n",
    "valid_data_gen.fit(valid_data)\n",
    "\n",
    "test_data = test_data/255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup VGG-16 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# reference: https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/\n",
    "num_classes = 7\n",
    "\n",
    "vgg16_model = VGG16(input_shape=(image_size,image_size,3), include_top = False, weights='imagenet')\n",
    "\n",
    "# don't use the pre-trained layers\n",
    "for layer in vgg16_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Flatten layer\n",
    "temp_layer = BatchNormalization()(vgg16_model.output)\n",
    "temp_layer = Flatten()(temp_layer)\n",
    "\n",
    "#Dense layer 1\n",
    "temp_layer = Dense(2048,activation='relu')(temp_layer)\n",
    "\n",
    "#Dense layer 2\n",
    "temp_layer = Dense(1024,activation='relu')(temp_layer)\n",
    "\n",
    "#output layer\n",
    "temp_layer = Dense(7,activation='softmax')(temp_layer)\n",
    "\n",
    "model = Model(vgg16_model.input,temp_layer)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Adam optimizer with 0.001 weights decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(learning_rate=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModelCheckpoint: save the best result\n",
    "# EarlyStopping: stop early if there is no change in \"val_acc\" after 150 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "check_point = ModelCheckpoint(\"../models/VGG_16.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, patience=100, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_weights('../models/VGG_16_weight.h5')\n",
    "except:\n",
    "    print(\"new model\")\n",
    "epochs = 200\n",
    "\n",
    "train_history = model.fit(\n",
    "    data_gen.flow(train_data,train_label,batch_size=128),\n",
    "    validation_data=valid_data_gen.flow(valid_data,valid_label,batch_size=32),\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=len(train_data)/128,\n",
    "    verbose=2,callbacks=[check_point,early_stop])\n",
    "\n",
    "model.save_weights('../models/VGG_16_weight.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def plot_model_accuracy(train_history, path):\n",
    "    plt.plot(train_history.history['acc'])\n",
    "    plt.plot(train_history.history['val_acc'])\n",
    "    plt.title('Model Accuracy')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend(['train', 'validation'], loc = 'upper left')\n",
    "    plt.savefig(path)\n",
    "    plt.show()\n",
    "    \n",
    "def plot_model_loss(train_history, path):\n",
    "    plt.plot(train_history.history['loss'])\n",
    "    plt.plot(train_history.history['val_loss'])\n",
    "    plt.title(\"Model Loss\")\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epochs')\n",
    "    plt.legend(['train', 'validation'], loc = 'upper left')\n",
    "    plt.savefig(path)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_model_accuracy(train_history,'../plots/VGG_16_training_history.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_model_loss(train_history, '../plots/VGG_16_training_loss.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(test_data, test_label)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(test_data)\n",
    "\n",
    "prediction_class = np.argmax(prediction,axis=1)\n",
    "prediction_label = np.argmax(test_label,axis=1)\n",
    "\n",
    "mapping = lambda x:features_dict[x]\n",
    "pred_class_to_feature = np.array([mapping(x) for x in prediction_class])\n",
    "pred_label_to_feature = np.array([mapping(x) for x in prediction_label])\n",
    "\n",
    "print(pd.crosstab(pred_label_to_feature,pred_class_to_feature,rownames=['actual'],colnames=['predicted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# inceptionV3 model to analysis the data\n",
    "# Applied oversampling for the imbalance data.\n",
    "## https://arxiv.org/abs/1409.1556"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup InceptionV3 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# reference: https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/\n",
    "num_classes = 7\n",
    "dimension = image_size*image_size*3\n",
    "\n",
    "InceptionV3_model = InceptionV3(input_shape=(image_size,image_size,3), include_top=False, weights='imagenet')\n",
    "\n",
    "# don't use the pre-trained model\n",
    "for layer in InceptionV3_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Flatten layer\n",
    "temp_layer = BatchNormalization()(InceptionV3_model.output)\n",
    "temp_layer = Flatten()(temp_layer)\n",
    "\n",
    "#Dense layer 1\n",
    "temp_layer = Dense(1024,activation='relu')(temp_layer)\n",
    "\n",
    "#output layer\n",
    "temp_layer = Dense(7,activation='softmax')(temp_layer)\n",
    "\n",
    "model = Model(InceptionV3_model.input,temp_layer)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModelCheckpoint: save the best result\n",
    "# EarlyStopping: stop early if there is no change in \"val_acc\" after 150 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "check_point = ModelCheckpoint(\"../models/InceptionV3.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, patience=100, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_weights('../models/InceptionV3_weight.h5')\n",
    "except:\n",
    "    print(\"new model\")\n",
    "\n",
    "epochs = 50\n",
    "\n",
    "train_history = model.fit(\n",
    "    data_gen.flow(train_data,train_label,batch_size=128),\n",
    "    validation_data=valid_data_gen.flow(valid_data,valid_label,batch_size=32),\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=len(train_data)/128,\n",
    "    verbose=2,callbacks=[check_point,early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights('../models/InceptionV3_weight.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_model_accuracy(train_history,'../plots/InceptionV3_training_history.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_model_loss(train_history, '../plots/InceptionV3_training_loss.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(test_data, test_label)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(test_data)\n",
    "\n",
    "prediction_class = np.argmax(prediction,axis=1)\n",
    "prediction_label = np.argmax(test_label,axis=1)\n",
    "\n",
    "mapping = lambda x:features_dict[x]\n",
    "pred_class_to_feature = np.array([mapping(x) for x in prediction_class])\n",
    "pred_label_to_feature = np.array([mapping(x) for x in prediction_label])\n",
    "\n",
    "print(pd.crosstab(pred_label_to_feature,pred_class_to_feature,rownames=['actual'],colnames=['predicted']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Efficient model to analysis the data\n",
    "## https://arxiv.org/abs/1409.1556"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup Efficient Net model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# reference: https://www.analyticsvidhya.com/blog/2020/08/top-4-pre-trained-models-for-image-classification-with-python-code/\n",
    "num_classes = 7\n",
    "dimension = image_size*image_size*3\n",
    "\n",
    "EN_model = ef.EfficientNetB0(input_shape=(image_size,image_size,3), include_top=False, weights='imagenet')\n",
    "for layer in EN_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "#Flatten layer\n",
    "temp_layer = BatchNormalization()(EN_model.output)\n",
    "temp_layer = Flatten()(temp_layer)\n",
    "\n",
    "#Dense layer 1\n",
    "temp_layer = Dense(1024,activation='relu')(temp_layer)\n",
    "\n",
    "#output layer\n",
    "temp_layer = Dense(7,activation='softmax')(temp_layer)\n",
    "\n",
    "model = Model(EN_model.input,temp_layer)\n",
    "#model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = Adam(lr=0.0001)\n",
    "model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['acc'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ModelCheckpoint: save the best result\n",
    "# EarlyStopping: stop early if there is no change in \"val_acc\" after 150 runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "check_point = ModelCheckpoint(\"../models/Efficient_Net.h5\", monitor='val_acc', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\n",
    "early_stop = EarlyStopping(monitor='val_acc', min_delta=0, patience=100, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model.load_weights('../models/Efficient_Net_weight.h5')\n",
    "except:\n",
    "    print(\"new model\")\n",
    "epochs = 100\n",
    "\n",
    "train_history = model.fit(\n",
    "    data_gen.flow(train_data,train_label,batch_size=128),\n",
    "    validation_data=valid_data_gen.flow(valid_data,valid_label,batch_size=32),\n",
    "    epochs=epochs,\n",
    "    steps_per_epoch=len(train_data)/128,\n",
    "    verbose=2,callbacks=[check_point,early_stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model.save_weights('../models/Efficient_Net_weight.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_model_accuracy(train_history,'../plots/Efficient_Net_training_history.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_model_loss(train_history, '../plots/Efficient_Net_training_loss.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "score = model.evaluate(test_data, test_label)\n",
    "print('Test accuracy:', score[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(test_data)\n",
    "\n",
    "prediction_class = np.argmax(prediction,axis=1)\n",
    "prediction_label = np.argmax(test_label,axis=1)\n",
    "\n",
    "mapping = lambda x:features_dict[x]\n",
    "pred_class_to_feature = np.array([mapping(x) for x in prediction_class])\n",
    "pred_label_to_feature = np.array([mapping(x) for x in prediction_label])\n",
    "\n",
    "print(pd.crosstab(pred_label_to_feature,pred_class_to_feature,rownames=['actual'],colnames=['predicted']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
